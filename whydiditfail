#!/usr/bin/env python3
"""
Azure DevOps RunRegression Pipeline Viewer
Shows pipeline runs and their failed tests using curses UI.
"""

import curses
import os
import sys
import requests
from requests.auth import HTTPBasicAuth
from base64 import b64encode
from typing import List, Dict, Any, Optional
from datetime import datetime


class AzDoConnection:
    """Handles Azure DevOps API connection and requests."""

    def __init__(self):
        """Initialize connection using environment variables."""
        self.pat_token = os.getenv("AZURE_DEVOPS_EXT_PAT")
        self.org_url = os.getenv("AZ_ORG")
        self.project = os.getenv("AZ_PROJECT")

        if not all([self.pat_token, self.org_url, self.project]):
            raise ValueError(
                "Missing required environment variables: "
                "AZURE_DEVOPS_EXT_PAT, AZ_ORG, AZ_PROJECT"
            )

        # Create authenticated session
        self.session = requests.Session()
        self.session.auth = HTTPBasicAuth("", self.pat_token)
        self.session.headers.update({
            "Content-Type": "application/json",
            "Accept": "application/json"
        })

    def make_request(self, url: str) -> Dict[str, Any]:
        """Make an authenticated GET request to Azure DevOps API."""
        response = self.session.get(url, timeout=120)
        response.raise_for_status()
        return response.json()

    def find_pipeline_by_name(self, name: str) -> Optional[int]:
        """Find a pipeline ID by name."""
        url = f"{self.org_url}/{self.project}/_apis/build/definitions?api-version=6.0"
        data = self.make_request(url)

        for pipeline in data.get("value", []):
            if pipeline["name"] == name:
                return pipeline["id"]

        return None

    def get_pipeline_runs(self, pipeline_id: int, top: int = 50) -> List[Dict[str, Any]]:
        """Get recent runs for a pipeline."""
        url = (
            f"{self.org_url}/{self.project}/_apis/build/builds?"
            f"definitions={pipeline_id}&$top={top}&api-version=6.0"
        )
        data = self.make_request(url)
        return data.get("value", [])

    def get_failed_tests(self, build_id: int) -> List[Dict[str, Any]]:
        """Get failed tests for a build, similar to get_portal_failures.py."""
        # Default filters for specific test suites
        default_filters = [
            'WindowsDriver',
            'AntiTamper',
            'AgentProtection',
            'AppControl',
            'AppMatching',
            'AppMatchingUninstallers',
            'AppPrivMan',
            'BeyondInsightIntegration',
            'Compatibility',
            'ContentControl',
            'ContentMatching',
            'ContentPrivMan',
            'DLLControl',
            'EndpointApp',
            'EventAuditJson',
            'EventAuditLegacy',
            'EventAuditWindowsEvents',
            'FileInformationCaching',
            'Filters',
            'Identity',
            'JITAdmin',
            'JITApplicationAccess',
            'Licensing',
            'Messaging',
            'OnDemand',
            'PasswordSafe',
            'Personas',
            'PowerRules',
            'RegistryKeys',
            'TAP',
            'UAC',
            'Upgrading',
            'Utilities'
        ]

        # Get build details to find time range
        build_url = f"{self.org_url}/{self.project}/_apis/build/builds/{build_id}?api-version=6.0"
        build_data = self.make_request(build_url)

        start_time = build_data.get('startTime')
        finish_time = build_data.get('finishTime')

        if not start_time or not finish_time:
            return []

        # Query test runs by the build's time range (not buildIds which returns historical data)
        runs_url = (
            f"{self.org_url}/{self.project}/_apis/test/runs?"
            f"minLastUpdatedDate={start_time}&maxLastUpdatedDate={finish_time}&api-version=7.0"
        )

        runs_data = self.make_request(runs_url)

        if not runs_data.get('value'):
            return []

        # Filter to only completed runs
        completed_runs = [
            r for r in runs_data['value']
            if r.get('state') == 'Completed'
        ]

        # Group by run name and get the one with highest ID (most recent)
        latest_runs = {}
        for run in completed_runs:
            run_name = run.get('name', 'Unknown')
            run_id = run['id']

            # Apply default filters - only include specified test suites
            if not any(f in run_name for f in default_filters):
                continue

            # Keep the run with the highest ID for each name
            if run_name not in latest_runs or run_id > latest_runs[run_name]['id']:
                latest_runs[run_name] = run

        # Get failures from each run
        all_failures = []

        for run_name in sorted(latest_runs.keys()):
            run = latest_runs[run_name]
            run_id = run['id']

            # Get failed test results for this run
            results_url = (
                f"{self.org_url}/{self.project}/_apis/test/Runs/{run_id}/results?"
                f"outcomes=Failed&$top=1000&api-version=7.0"
            )

            try:
                results_data = self.make_request(results_url)
            except requests.exceptions.Timeout:
                continue

            # Count actual failures
            for result in results_data.get('value', []):
                outcome = result.get('outcome', '')

                # Only include tests with outcome exactly "Failed"
                if outcome != 'Failed':
                    continue

                test_name = result.get(
                    'testCaseTitle',
                    result.get('automatedTestName', 'Unknown')
                )
                error_message = result.get('errorMessage', '')

                all_failures.append({
                    'run': run_name,
                    'test': test_name,
                    'run_id': run_id,
                    'result_id': result['id'],
                    'error': error_message
                })

        return all_failures

    def get_build_timeline(self, build_id: int) -> Dict[str, Any]:
        """Get the build timeline to find job IDs."""
        url = (
            f"{self.org_url}/{self.project}/_apis/build/builds/{build_id}/"
            f"timeline?api-version=6.0"
        )
        return self.make_request(url)

    def find_copy_task_ids(self, build_id: int) -> List[tuple]:
        """Find all 'Copy test results locally' task IDs and their log IDs."""
        timeline = self.get_build_timeline(build_id)

        copy_tasks = []
        for record in timeline.get('records', []):
            if record.get('type') == 'Task':
                task_name = record.get('name', '')
                if 'Copy test results locally' in task_name:
                    log_ref = record.get('log', {})
                    log_id = log_ref.get('id')
                    if log_id:
                        copy_tasks.append((record.get('id'), log_id))

        return copy_tasks

    def get_build_logs(self, build_id: int, log_id: int) -> List[str]:
        """Download and return the log lines from a build log."""
        url = (
            f"{self.org_url}/{self.project}/_apis/build/builds/{build_id}/"
            f"logs/{log_id}?api-version=6.0"
        )
        response = self.session.get(url, timeout=120)
        response.raise_for_status()
        log_data = response.json()
        return log_data.get('value', [])

    def parse_copy_job_logs(self, build_id: int) -> Dict[str, str]:
        """
        Parse 'Copy test results locally' task logs to extract UNC paths.
        Returns a dict mapping test suite names to their UNC paths.
        """
        import re

        # Find all Copy tasks
        copy_tasks = self.find_copy_task_ids(build_id)
        if not copy_tasks:
            return {}

        # Parse logs for UNC paths
        # Pattern: Copying \\fs01.btrusteng.com\ExecutionProduction\PMfW Regression - <TestSuite>\<GUID>\Endpoints
        # Note: In the JSON log, backslashes appear as single \ not \\
        pattern = r'Copying \\\\fs01\.btrusteng\.com\\ExecutionProduction\\PMfW Regression - ([^\\]+)\\([a-f0-9-]{36})\\Endpoints'

        test_suite_paths = {}

        # Parse logs from all copy tasks
        for task_id, log_id in copy_tasks:
            try:
                log_lines = self.get_build_logs(build_id, log_id)

                # Search through all log lines
                for line in log_lines:
                    match = re.search(pattern, line)
                    if match:
                        test_suite = match.group(1)
                        guid = match.group(2)
                        unc_path = f"\\\\fs01.btrusteng.com\\ExecutionProduction\\PMfW Regression - {test_suite}\\{guid}\\Endpoints"
                        test_suite_paths[test_suite] = unc_path
                        # Found the path for this task, move to next task
                        break

            except Exception:
                # Skip tasks that fail to download
                continue

        return test_suite_paths

    def copy_unc_artifacts(self, unc_path: str, output_dir: str) -> tuple[List[str], bool]:
        """
        Recursively scan UNC path for .zip, .dmp, and Results.trx files and copy them to output_dir.
        Preserves relative directory structure from the endpoint folder.
        Results.trx files are copied to the root of output_dir.
        Returns tuple of (list of copied filenames, whether ProcDump folder was found).
        """
        import os
        import shutil
        from pathlib import Path

        copied_files = []
        has_procdump = False

        try:
            unc_source = Path(unc_path)
            output_path = Path(output_dir)

            # Check if UNC path is accessible
            if not unc_source.exists():
                print(f"DEBUG: UNC path does not exist: {unc_path}")
                return copied_files, has_procdump  # Return empty if UNC path not accessible

            print(f"DEBUG: UNC path accessible: {unc_path}")

            # Walk through the UNC directory tree
            for root, dirs, files in os.walk(unc_source):
                root_path = Path(root)

                # Check if any directory is named ProcDump
                if 'ProcDump' in dirs:
                    has_procdump = True
                    print(f"DEBUG: Found ProcDump folder at {root_path / 'ProcDump'}")

                # Calculate relative path from the UNC source
                try:
                    rel_path = root_path.relative_to(unc_source)
                except ValueError:
                    # Skip if we can't determine relative path
                    continue

                for filename in files:
                    # Copy .zip and .dmp files preserving directory structure
                    if filename.lower().endswith(('.zip', '.dmp')):
                        source_file = root_path / filename

                        # Create destination path preserving directory structure
                        dest_dir = output_path / rel_path
                        dest_dir.mkdir(parents=True, exist_ok=True)
                        dest_file = dest_dir / filename

                        # Copy the file
                        try:
                            shutil.copy2(source_file, dest_file)
                            copied_files.append(filename)
                            print(f"DEBUG: Copied {filename} to {dest_dir}")
                        except Exception as e:
                            print(f"DEBUG: Failed to copy {filename}: {e}")
                            # Skip files that fail to copy
                            continue
                    
                    # Copy Results.trx files to root of output directory
                    elif filename == 'Results.trx':
                        source_file = root_path / filename
                        
                        # Copy to root of output directory
                        dest_file = output_path / filename
                        
                        # If Results.trx already exists, append a number
                        if dest_file.exists():
                            counter = 1
                            while (output_path / f'Results_{counter}.trx').exists():
                                counter += 1
                            dest_file = output_path / f'Results_{counter}.trx'
                        
                        try:
                            shutil.copy2(source_file, dest_file)
                            copied_files.append(filename)
                            print(f"DEBUG: Copied {filename} to {dest_file}")
                        except Exception as e:
                            print(f"DEBUG: Failed to copy {filename}: {e}")
                            continue

            print(f"DEBUG: Total files copied: {len(copied_files)}, ProcDump found: {has_procdump}")

        except Exception as e:
            print(f"DEBUG: Exception in copy_unc_artifacts: {e}")
            # Silently skip if any errors occur accessing UNC path
            pass

        return copied_files, has_procdump

    def get_build_version(self, build_id: int) -> Optional[str]:
        """
        Extract the build version from 'Get Version' job logs.
        Looks for a line like "Build Number 25.9.44.0"
        """
        import re

        timeline = self.get_build_timeline(build_id)

        # Find the "Get build info" task in the "Get Version" job
        for record in timeline.get('records', []):
            if record.get('type') == 'Task':
                task_name = record.get('name', '')
                if 'Get build info' in task_name:
                    log_ref = record.get('log', {})
                    log_id = log_ref.get('id')
                    print(f"DEBUG: Found 'Get build info' task, log ID: {log_id}")

                    if log_id:
                        try:
                            log_lines = self.get_build_logs(build_id, log_id)
                            print(f"DEBUG: Retrieved {len(log_lines)} log lines")

                            # Search for "Build Number X.X.X.X"
                            for line in log_lines:
                                match = re.search(r'Build Number (\d+\.\d+\.\d+\.\d+)', line)
                                if match:
                                    version = match.group(1)
                                    print(f"DEBUG: Extracted build version: {version}")
                                    return version
                        except Exception as e:
                            print(f"DEBUG: Exception getting build version: {e}")
                            continue

        print(f"DEBUG: No build version found in logs")
        return None

    def find_build_by_version(self, version: str) -> Optional[int]:
        """
        Search FullBuild and FeatureBuild pipelines for a build with matching version.
        Returns the build ID if found.
        """
        pipeline_names = ["FullBuild", "FeatureBuild"]

        print(f"DEBUG: Searching for build with version {version}")
        for pipeline_name in pipeline_names:
            # Find pipeline ID
            pipeline_id = self.find_pipeline_by_name(pipeline_name)
            if not pipeline_id:
                print(f"DEBUG: Pipeline '{pipeline_name}' not found")
                continue

            print(f"DEBUG: Searching {pipeline_name} (ID: {pipeline_id})")
            # Get recent builds (search up to 100)
            try:
                builds = self.get_pipeline_runs(pipeline_id, top=100)
                print(f"DEBUG: Found {len(builds)} builds in {pipeline_name}")

                for build in builds[:5]:  # Log first 5 for debugging
                    build_number = build.get('buildNumber', '')
                    print(f"DEBUG:   Checking build: {build_number}")

                for build in builds:
                    build_number = build.get('buildNumber', '')
                    # Check if version is in the build number
                    if version in build_number:
                        print(f"DEBUG: MATCH FOUND! Build {build['id']}: {build_number}")
                        return build['id']
            except Exception as e:
                print(f"DEBUG: Exception searching {pipeline_name}: {e}")
                continue

        print(f"DEBUG: No build found with version {version}")
        return None

    def recursive_unzip(self, zip_path: str, output_dir: str, depth: int = 0, max_depth: int = 3):
        """
        Recursively extract zip files. If a zip contains another zip, extract it too.
        Platform-specific zips (ARM64, x64, x86) are extracted to their own subfolders.
        """
        import zipfile
        import os
        from pathlib import Path
        import re

        # Prevent infinite recursion
        if depth >= max_depth:
            print(f"DEBUG: Max recursion depth {max_depth} reached, stopping")
            return

        output_path = Path(output_dir)
        zip_file_path = Path(zip_path)

        if not zip_file_path.exists():
            print(f"DEBUG: Zip file doesn't exist: {zip_path}")
            return

        print(f"DEBUG: [Depth {depth}] Extracting {zip_file_path.name} to {output_path}")

        try:
            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
                zip_ref.extractall(output_path)

            # Track which zip files we've already processed
            processed_zips = set()

            # Find any nested zip files and extract them
            for root, dirs, files in os.walk(output_path):
                root_path = Path(root)
                for filename in files:
                    if filename.lower().endswith('.zip'):
                        nested_zip = root_path / filename

                        # Skip if already processed
                        if str(nested_zip) in processed_zips:
                            continue
                        processed_zips.add(str(nested_zip))

                        # Determine if this is a platform-specific zip
                        # Pattern: *_ARM64_*.zip, *_x64_*.zip, *_x86_*.zip
                        platform_match = re.search(r'_(ARM64|x64|x86)_', filename, re.IGNORECASE)

                        if platform_match:
                            platform = platform_match.group(1)
                            # Extract to platform-specific subfolder
                            extract_dir = root_path / platform
                            print(f"DEBUG: [Depth {depth}] Found platform-specific zip: {filename} -> {platform}/")
                        else:
                            # Extract in the same directory as the zip file
                            extract_dir = root_path
                            print(f"DEBUG: [Depth {depth}] Found nested zip: {filename}")

                        extract_dir.mkdir(parents=True, exist_ok=True)

                        try:
                            self.recursive_unzip(str(nested_zip), str(extract_dir), depth + 1, max_depth)
                            # Remove the zip file after extraction
                            nested_zip.unlink()
                            print(f"DEBUG: [Depth {depth}] Deleted {filename} after extraction")
                        except Exception as e:
                            print(f"DEBUG: [Depth {depth}] Failed to extract {filename}: {e}")
                            # Skip if extraction fails
                            continue

        except Exception as e:
            print(f"DEBUG: [Depth {depth}] Exception extracting {zip_file_path.name}: {e}")
            # Skip if extraction fails
            pass

    def extract_procdump_files(self, output_dir: str):
        """
        Extract all zip files in the ProcDump folder into subdirectories and create WinDbg batch files for dumps.
        Each dump file gets extracted to its own subdirectory, and batch files are created in the root failure folder.
        Searches recursively for ProcDump folders if not found at the root.
        """
        import zipfile
        from pathlib import Path

        output_path = Path(output_dir)
        
        # Search for ProcDump folder - try root first, then search recursively
        procdump_dir = output_path / 'ProcDump'
        if not procdump_dir.exists():
            # Search for ProcDump folder in subdirectories
            print(f"DEBUG: ProcDump not found at root, searching subdirectories...")
            procdump_dirs = list(output_path.rglob('ProcDump'))
            
            if not procdump_dirs:
                print(f"DEBUG: No ProcDump folder found anywhere in {output_dir}")
                return
            
            # Use the first ProcDump folder found
            procdump_dir = procdump_dirs[0]
            print(f"DEBUG: Found ProcDump folder at: {procdump_dir}")
        else:
            print(f"DEBUG: Found ProcDump folder at root: {procdump_dir}")

        print(f"DEBUG: Processing ProcDump folder: {procdump_dir}")

        # Find and extract all dump files in ProcDump folder (including zips)
        # First, extract all zip files to subdirectories
        for zip_file in procdump_dir.glob('*.zip'):
            print(f"DEBUG: Extracting {zip_file.name}")
            # Extract to subfolder with same name as zip (without .zip extension)
            extract_dir = procdump_dir / zip_file.stem
            extract_dir.mkdir(parents=True, exist_ok=True)

            try:
                with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                    zip_ref.extractall(extract_dir)
                print(f"DEBUG: Extracted to {extract_dir}")

                # Delete zip after extraction
                zip_file.unlink()
                print(f"DEBUG: Deleted {zip_file.name}")
            except Exception as e:
                print(f"DEBUG: Failed to extract {zip_file.name}: {e}")
                continue

        # Also extract standalone .dmp files to their own subdirectories
        for dmp_file in procdump_dir.glob('*.dmp'):
            print(f"DEBUG: Moving standalone dump {dmp_file.name} to subdirectory")
            # Create subdirectory for this dump file
            dump_subdir = procdump_dir / dmp_file.stem
            dump_subdir.mkdir(parents=True, exist_ok=True)
            
            # Move the dump file into its subdirectory
            try:
                new_location = dump_subdir / dmp_file.name
                dmp_file.rename(new_location)
                print(f"DEBUG: Moved {dmp_file.name} to {dump_subdir}")
            except Exception as e:
                print(f"DEBUG: Failed to move {dmp_file.name}: {e}")
                continue

        # Find all .dmp files in ProcDump folder (now in subdirectories) and create batch files
        dump_files = list(procdump_dir.rglob('*.dmp'))
        print(f"DEBUG: Found {len(dump_files)} dump files")

        pdbs_dir = output_path / 'pdbs'

        # Build symbol path once for all dumps
        symbol_paths = []
        if pdbs_dir.exists():
            # Recursively find all directories containing .pdb files
            pdb_dirs = set()
            for pdb_file in pdbs_dir.rglob('*.pdb'):
                pdb_dirs.add(str(pdb_file.parent.resolve()))
            
            # Add all unique directories containing pdb files
            symbol_paths.extend(sorted(pdb_dirs))
            
            # Also add main pdbs folder and common architecture folders if they exist
            if str(pdbs_dir.resolve()) not in symbol_paths:
                symbol_paths.insert(0, str(pdbs_dir.resolve()))

        # Add Microsoft symbol server (always include this)
        symbol_paths.append('srv*C:\\pdbs*https://msdl.microsoft.com/download/symbols')
        symbol_path = ';'.join(symbol_paths)

        for dump_file in dump_files:
            # Create WinDbg batch file in root of output_dir (failure folder root)
            windbg_batch_name = f"debug_{dump_file.stem}.bat"
            windbg_batch_file = output_path / windbg_batch_name

            # Create WinDbg batch file
            windbg_batch_content = f'''@echo off
REM Auto-generated WinDbg launcher for {dump_file.name}
set _NT_SYMBOL_PATH={symbol_path}
"C:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\windbg.exe" -z "{dump_file.resolve()}"
'''

            try:
                with open(windbg_batch_file, 'w') as f:
                    f.write(windbg_batch_content)
                print(f"DEBUG: Created {windbg_batch_name} for {dump_file.name}")
            except Exception as e:
                print(f"DEBUG: Failed to create WinDbg batch file for {dump_file.name}: {e}")

            # Create KD batch file for command-line debugging (LLM-friendly)
            kd_batch_name = f"kd_{dump_file.stem}.bat"
            kd_batch_file = output_path / kd_batch_name

            # Create KD batch file
            kd_batch_content = f'''@echo off
REM Auto-generated KD (Kernel Debugger) launcher for {dump_file.name}
REM KD provides a command-line interface suitable for LLM interaction
set _NT_SYMBOL_PATH={symbol_path}
"C:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\kd.exe" -z "{dump_file.resolve()}"
'''

            try:
                with open(kd_batch_file, 'w') as f:
                    f.write(kd_batch_content)
                print(f"DEBUG: Created {kd_batch_name} for {dump_file.name}")
            except Exception as e:
                print(f"DEBUG: Failed to create KD batch file for {dump_file.name}: {e}")

            # Run WinDbg in headless mode to capture !analyze -v output
            print(f"DEBUG: Running !analyze -v for {dump_file.name}...")
            try:
                self.run_windbg_analysis(dump_file, symbol_path, output_path)
            except Exception as e:
                print(f"DEBUG: Failed to run analysis for {dump_file.name}: {e}")

    def run_windbg_analysis(self, dump_file, symbol_path: str, output_dir):
        """
        Run WinDbg in headless mode to execute !analyze -v on a dump file.
        Saves the output to analysis_{dump_name}.txt in the output directory.
        """
        import subprocess
        import tempfile
        from pathlib import Path
        
        output_path = Path(output_dir)
        dump_path = Path(dump_file)
        
        # Output file for the analysis
        analysis_file = output_path / f"analysis_{dump_path.stem}.txt"
        
        # Create a temporary script file for WinDbg commands
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as script_file:
            # WinDbg script: run !analyze -v and quit
            script_file.write('.logopen "{}"\n'.format(analysis_file.resolve()))
            script_file.write('!analyze -v\n')
            script_file.write('.logclose\n')
            script_file.write('q\n')  # quit
            script_path = script_file.name
        
        try:
            # Build WinDbg command
            # Use cdb.exe (console debugger) instead of windbg.exe for headless operation
            cdb_path = r"C:\Program Files (x86)\Windows Kits\10\Debuggers\x64\cdb.exe"
            
            # Command: cdb -z <dump> -c "<commands>"
            # Alternative: use -cf <script_file> for command file
            cmd = [
                cdb_path,
                '-z', str(dump_path.resolve()),
                '-y', symbol_path,  # Symbol path
                '-cf', script_path,  # Command file
                '-logo', str(analysis_file.resolve())  # Log output
            ]
            
            print(f"DEBUG: Running: {' '.join(cmd[:3])}...")
            
            # Run the debugger with a timeout (some dumps may take a while)
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300,  # 5 minute timeout
                env={**subprocess.os.environ, '_NT_SYMBOL_PATH': symbol_path}
            )
            
            print(f"DEBUG: Analysis completed for {dump_path.name}")
            print(f"DEBUG: Output saved to {analysis_file.name}")
            
            # If the log file wasn't created by .logopen, save stdout/stderr
            if not analysis_file.exists() or analysis_file.stat().st_size == 0:
                with open(analysis_file, 'w') as f:
                    f.write("=== WinDbg Analysis Output ===\n\n")
                    if result.stdout:
                        f.write(result.stdout)
                    if result.stderr:
                        f.write("\n\n=== Errors ===\n")
                        f.write(result.stderr)
                print(f"DEBUG: Saved captured output to {analysis_file.name}")
            
        except subprocess.TimeoutExpired:
            print(f"DEBUG: Analysis timed out for {dump_path.name}")
            # Create a file noting the timeout
            with open(analysis_file, 'w') as f:
                f.write(f"Analysis timed out after 300 seconds for {dump_path.name}\n")
        except FileNotFoundError:
            print(f"DEBUG: WinDbg/CDB not found at expected location")
            # Create a file noting the issue
            with open(analysis_file, 'w') as f:
                f.write(f"WinDbg/CDB not found. Please ensure Windows Debugging Tools are installed.\n")
                f.write(f"Expected location: {cdb_path}\n")
        except Exception as e:
            print(f"DEBUG: Exception during analysis: {e}")
            # Create a file noting the error
            with open(analysis_file, 'w') as f:
                f.write(f"Error during analysis: {str(e)}\n")
        finally:
            # Clean up temporary script file
            try:
                Path(script_path).unlink()
            except:
                pass

    def create_debugging_documentation(self, output_dir: str, build_id: int, test_name: str, build_version: Optional[str] = None, commit_sha: Optional[str] = None):
        """
        Create a Debugging.md file in the test failure folder with comprehensive debugging guidance.
        This documentation is designed to help LLMs (like Claude or Copilot) debug the test failure.
        """
        from pathlib import Path
        
        output_path = Path(output_dir)
        debugging_md = output_path / 'Debugging.md'
        
        # Find available files in the output directory
        has_dumps = len(list(output_path.rglob('*.dmp'))) > 0
        kd_batches = sorted(list(output_path.glob('kd_*.bat')))
        analysis_files = sorted(list(output_path.glob('analysis_*.txt')))
        has_standard_output = (output_path / 'Standard_Console_Output.log').exists()
        has_results_trx = len(list(output_path.glob('*.trx'))) > 0
        has_screenshots = len(list(output_path.glob('screenshot*.png'))) > 0
        has_debuglogs = len(list(output_path.glob('debuglog*.log'))) > 0
        has_screencapture = (output_path / 'ScreenCapture.wmv').exists()
        
        content = f"""# Debugging Guide for Test Failure

## Test Information

**Test Name:** `{test_name}`  
**Build ID:** `{build_id}`  
"""

        if build_version:
            content += f"**Build Version:** `{build_version}`  \n"
        
        if commit_sha:
            content += f"**Commit SHA:** `{commit_sha}`  \n"
        
        content += """
**Source Code Location:** `Z:\\epm-windows`  
**Test Source Code Location:** `Z:\\epm-windows\\Tests\\Automation`

---

## Quick Start

This test has failed and requires debugging. Start by reviewing the logs in order of priority:

"""

        # Priority order based on available files
        priority = 1
        
        if has_standard_output:
            content += f"{priority}. **Standard_Console_Output.log** - Start here first\n"
            priority += 1
        
        if analysis_files:
            content += f"{priority}. **analysis_*.txt** - Automated crash analysis (if crashes occurred)\n"
            priority += 1
        
        if has_results_trx:
            content += f"{priority}. **Results.trx** - Full VSTest information including setup/teardown\n"
            priority += 1
        
        if has_screenshots:
            content += f"{priority}. **screenshot*.png** - Visual evidence of test state\n"
            priority += 1
        
        if has_screencapture:
            content += f"{priority}. **ScreenCapture.wmv** - Video recording of the test execution\n"
            priority += 1
        
        if has_debuglogs:
            content += f"{priority}. **debuglog*.log** - Detailed client trace (verbose)\n"
            priority += 1
        
        content += """
---

## Available Debugging Resources

### 1. Standard Console Output (Primary Log)

**File:** `Standard_Console_Output.log`

This is the standard output from VSTest and should be **the first thing you examine**. It contains:
- Test execution output
- Console messages from the test
- Initial error messages and stack traces
- Test framework diagnostics

### 2. Test Results File

**File:** `Results.trx`

The VSTest results file in TRX (XML) format containing:
- Complete test execution details
- Test setup and teardown information
- Timing information
- Error messages and stack traces
- Test properties and metadata

This file provides structured information about what happened during the test lifecycle.

"""

        if has_dumps:
            content += """### 3. Crash Dumps and Interactive Debugging

"""
            if kd_batches:
                content += f"""**Available Crash Dumps:** {len(kd_batches)}

The following batch files will launch an interactive KD debugger session with all symbols loaded:

"""
                for kd_batch in kd_batches:
                    dump_name = kd_batch.stem.replace('kd_', '')
                    content += f"- **{kd_batch.name}** - Debug `{dump_name}.dmp` interactively\n"
                
                content += """
**To use the KD debugger:**

1. Run one of the batch files above (e.g., `kd_crash_name.bat`)
2. The debugger will launch with symbols already loaded
3. Common commands:
   - `!analyze -v` - Detailed crash analysis
   - `k` - View call stack
   - `lm` - List loaded modules
   - `!threads` - List all threads
   - `~*k` - Stack traces for all threads
   - `.ecxr` - Set context to exception
   - `q` - Quit debugger

**Symbol Path:** All PDB files from the build are already included in the symbol path, plus the Microsoft symbol server.

"""
            
            if analysis_files:
                content += f"""**Automated Crash Analysis:**

The following files contain automated `!analyze -v` output from WinDbg:

"""
                for analysis_file in analysis_files:
                    content += f"- **{analysis_file.name}** - Pre-generated crash analysis\n"
                
                content += """
Review these files first before launching the interactive debugger to understand the crash.

"""

        if has_screenshots:
            content += """### 4. Screenshots

**Files:** `screenshot*.png`

Screenshots captured during test execution showing the visual state of the application or test environment at various points.

"""

        if has_debuglogs:
            content += """### 5. Debug Logs (Client Trace)

**Files:** `debuglog*.log`

Detailed trace logs from the service/client itself. **Warning:** These logs are typically very long and detailed.

Use these logs when:
- You need to understand internal service operations
- The Standard_Console_Output doesn't provide enough detail
- You're tracking down timing or state issues

"""

        if has_screencapture:
            content += """### 6. Screen Capture Video

**File:** `ScreenCapture.wmv`

A video recording of the entire test execution. Useful for:
- Understanding the visual sequence of events
- Identifying UI-related issues
- Seeing exactly what happened leading up to the failure

"""

        content += """---

## Your Task

**Debug this failing test and document your findings.**

Fully review all log files and perform complex dump analysis if needed.  You have both symbols and the source code.

### Analysis Output Location

Save your analysis to:

```
~/testruns/{build_id}/analysis_{safe_test_name}.md
```

Replace `{safe_test_name}` with a filesystem-safe version of the test name (spaces replaced with underscores, special characters removed).

### Required Analysis Content

Your analysis should include:

1. **Detailed Description of the Problem**
   - What went wrong?
   - Where did the failure occur?
   - What was the expected vs. actual behavior?

2. **Root Cause**
   - Why did this failure occur?
   - What code or configuration caused the issue?
   - Include relevant file paths, line numbers, or log excerpts

3. **Proposed Resolution**
   - What could be done to fix this?
   - Are there multiple possible solutions?
   - What would be the recommended approach?

4. **Additional Context** (if applicable)
   - Are there related issues or patterns?
   - Is this a flaky test or consistent failure?
   - Are there any workarounds?

---

## Tips for Effective Debugging

1. **Start with Standard_Console_Output.log** - Most issues are evident here
2. **Check for crashes** - If dump files exist, review the automated analysis first
3. **Look for patterns** - Compare with previous test runs if available
4. **Verify assumptions** - Check that test preconditions were met
5. **Use the video** - ScreenCapture.wmv can reveal timing or UI issues
6. **Trace the flow** - Use debuglog*.log to understand internal operations
7. **Check the TRX file** - Setup/teardown issues often appear here

---

## Need More Information?

If you need additional context:
- Source code is in: `Z:\\epm-windows`
- Test source is in: `Z:\\epm-windows\\Tests\\Automation`
- Build artifacts and symbols are in the `pdbs/` folder
- Original test results are on the UNC path (see `UNC_Path.txt` if available)

---

*This debugging guide was automatically generated to assist with test failure analysis.*
"""

        # Write the documentation file
        try:
            with open(debugging_md, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"DEBUG: Created comprehensive debugging guide at {debugging_md}")
        except Exception as e:
            print(f"DEBUG: Failed to create Debugging.md: {e}")

    def download_service_symbols(self, build_id: int, output_dir: str):
        """
        Download _ServiceSymbols artifact from a build and extract to pdbs/ folder.
        """
        from pathlib import Path
        import tempfile

        output_path = Path(output_dir)
        pdbs_dir = output_path / 'pdbs'
        pdbs_dir.mkdir(parents=True, exist_ok=True)
        print(f"DEBUG: Created pdbs directory: {pdbs_dir}")

        try:
            # Get build artifacts
            artifacts_url = (
                f"{self.org_url}/{self.project}/_apis/build/builds/{build_id}/"
                f"artifacts?api-version=6.0"
            )
            print(f"DEBUG: Fetching artifacts from: {artifacts_url}")
            artifacts_data = self.make_request(artifacts_url)

            artifact_names = [a.get('name') for a in artifacts_data.get('value', [])]
            print(f"DEBUG: Found {len(artifact_names)} artifacts: {artifact_names}")

            # Find _ServiceSymbols artifact
            service_symbols_url = None
            for artifact in artifacts_data.get('value', []):
                if artifact.get('name') == '_ServiceSymbols':
                    service_symbols_url = artifact.get('resource', {}).get('downloadUrl')
                    print(f"DEBUG: Found _ServiceSymbols artifact: {service_symbols_url}")
                    break

            if not service_symbols_url:
                print(f"DEBUG: No _ServiceSymbols artifact found in build {build_id}")
                return  # No symbols artifact found

            # Download the artifact
            print(f"DEBUG: Downloading symbols artifact...")
            response = self.session.get(service_symbols_url, timeout=300)
            response.raise_for_status()
            print(f"DEBUG: Downloaded {len(response.content)} bytes")

            # Save to temporary file
            with tempfile.NamedTemporaryFile(delete=False, suffix='.zip') as tmp_file:
                tmp_file.write(response.content)
                tmp_path = tmp_file.name
            print(f"DEBUG: Saved to temp file: {tmp_path}")

            # Recursively extract
            print(f"DEBUG: Extracting symbols to {pdbs_dir}")
            self.recursive_unzip(tmp_path, str(pdbs_dir))

            # Clean up temp file
            Path(tmp_path).unlink()
            print(f"DEBUG: Symbols extraction complete")

        except Exception as e:
            print(f"DEBUG: Exception in download_service_symbols: {e}")
            import traceback
            traceback.print_exc()
            # Silently skip if download or extraction fails
            pass

    def create_windows_shortcut(self, unc_path: str, output_dir: str, endpoint: Optional[str] = None):
        """
        Create Windows shortcut files to the UNC path.
        Creates both a .bat file and a .txt file for compatibility.
        If endpoint is provided, it will be appended to the UNC path.
        """
        from pathlib import Path

        output_path = Path(output_dir)

        # Append endpoint to UNC path if provided
        if endpoint:
            full_unc_path = f"{unc_path}\\{endpoint}"
        else:
            full_unc_path = unc_path

        # Create a batch file that opens the UNC path in Windows Explorer
        bat_file = output_path / "Open_Test_Results.bat"
        with open(bat_file, 'w') as f:
            f.write(f'@echo off\n')
            f.write(f'start "" "{full_unc_path}"\n')

        # Create a text file with the UNC path for easy copying
        txt_file = output_path / "UNC_Path.txt"
        with open(txt_file, 'w') as f:
            f.write(f'Test Results Location:\n')
            f.write(f'{full_unc_path}\n')

    def download_test_logs(self, run_id: int, result_id: int, build_id: int, test_name: str, unc_path: Optional[str] = None) -> str:
        """Download logs for a failed test to ~/testruns/<buildid>/<testname>/"""
        import re
        from pathlib import Path

        # Sanitize test name for filesystem
        safe_test_name = re.sub(r'[^\w\-_\. ]', '_', test_name)
        safe_test_name = safe_test_name.replace(' ', '_')

        # Create directory structure
        output_dir = Path.home() / 'testruns' / str(build_id) / safe_test_name
        output_dir.mkdir(parents=True, exist_ok=True)

        # Get test result details with attachments
        result_url = (
            f"{self.org_url}/{self.project}/_apis/test/Runs/{run_id}/"
            f"Results/{result_id}?detailsToInclude=SubResults&api-version=7.0"
        )

        try:
            result_data = self.make_request(result_url)

            # Save test result details
            import json
            with open(output_dir / 'result.json', 'w') as f:
                json.dump(result_data, f, indent=2)

            # Get attachments
            attachments_url = (
                f"{self.org_url}/{self.project}/_apis/test/Runs/{run_id}/"
                f"Results/{result_id}/attachments?api-version=7.0"
            )

            attachments_data = self.make_request(attachments_url)

            # Download each attachment
            for attachment in attachments_data.get('value', []):
                attachment_id = attachment.get('id')
                attachment_name = attachment.get('fileName', f'attachment_{attachment_id}')

                attachment_url = (
                    f"{self.org_url}/{self.project}/_apis/test/Runs/{run_id}/"
                    f"Results/{result_id}/attachments/{attachment_id}?api-version=7.0"
                )

                response = self.session.get(attachment_url, timeout=120)
                response.raise_for_status()

                # Save attachment
                with open(output_dir / attachment_name, 'wb') as f:
                    f.write(response.content)

            # Also save error message to a text file
            if result_data.get('errorMessage'):
                with open(output_dir / 'error.txt', 'w') as f:
                    f.write(result_data['errorMessage'])

            # Create Windows shortcut to UNC path if provided
            if unc_path:
                # Extract endpoint (computer name) from result data
                endpoint = result_data.get('computerName')
                self.create_windows_shortcut(unc_path, str(output_dir), endpoint)

                # Copy .zip and .dmp files from UNC path if endpoint is available
                if endpoint:
                    full_unc_path = f"{unc_path}\\{endpoint}"
                    print(f"DEBUG: Copying artifacts from {full_unc_path}")
                    copied_files, has_procdump = self.copy_unc_artifacts(full_unc_path, str(output_dir))

                    # If ProcDump folder was found, download symbols
                    if has_procdump:
                        print(f"DEBUG: ProcDump folder detected, downloading symbols...")
                        # Get build version from the regression run
                        build_version = self.get_build_version(build_id)
                        print(f"DEBUG: Build version: {build_version}")
                        if build_version:
                            # Find the matching FullBuild or FeatureBuild
                            symbols_build_id = self.find_build_by_version(build_version)
                            print(f"DEBUG: Symbols build ID: {symbols_build_id}")
                            if symbols_build_id:
                                # Download and extract symbols
                                print(f"DEBUG: Downloading symbols from build {symbols_build_id}")
                                self.download_service_symbols(symbols_build_id, str(output_dir))
                                print(f"DEBUG: Symbols download complete")

                        # Extract ProcDump files and create WinDbg batch files
                        print(f"DEBUG: Extracting ProcDump files and creating debug batch files...")
                        self.extract_procdump_files(str(output_dir))
                        print(f"DEBUG: ProcDump extraction complete")
                    else:
                        print(f"DEBUG: No ProcDump folder found, skipping symbol download")

            # Create Debugging.md documentation file (do this last after all processing)
            print(f"DEBUG: Creating Debugging.md documentation...")
            # Get build version and commit info for documentation
            build_version = None
            commit_sha = None
            if unc_path and endpoint:
                # Try to get build version if not already retrieved
                if 'build_version' not in locals() or not build_version:
                    build_version = self.get_build_version(build_id)
            
            # Get commit SHA from build info
            try:
                build_url = f"{self.org_url}/{self.project}/_apis/build/builds/{build_id}?api-version=6.0"
                build_data = self.make_request(build_url)
                commit_sha = build_data.get('sourceVersion')
            except:
                pass
            
            self.create_debugging_documentation(str(output_dir), build_id, test_name, build_version, commit_sha)
            print(f"DEBUG: Debugging.md created")

            # Invoke copilot to perform debugging
            print(f"DEBUG: Invoking copilot for automated debugging...")
            try:
                import subprocess
                copilot_cmd = [
                    'copilot',
                    '-p', 'Perform the debugging discussed in Debugging.md',
                    '--allow-tool', 'write',
                    '--allow-all-tools',
                    '--add-dir', str(Path.home() / 'testruns'),
                    '--add-dir', 'z:\\epm-windows'
                ]
                # Run copilot from the output directory where Debugging.md is located
                result = subprocess.run(
                    copilot_cmd,
                    cwd=str(output_dir),
                    capture_output=True,
                    text=True,
                    timeout=1800  # 30 minute timeout for copilot analysis
                )
                print(f"DEBUG: Copilot completed with return code {result.returncode}")
                if result.stdout:
                    print(f"DEBUG: Copilot output: {result.stdout[:500]}")  # Print first 500 chars
                if result.stderr:
                    print(f"DEBUG: Copilot errors: {result.stderr[:500]}")
            except subprocess.TimeoutExpired:
                print(f"DEBUG: Copilot analysis timed out after 30 minutes")
            except FileNotFoundError:
                print(f"DEBUG: Copilot command not found - is it installed and in PATH?")
            except Exception as e:
                print(f"DEBUG: Exception invoking copilot: {e}")

            return str(output_dir)

        except Exception as e:
            raise Exception(f"Failed to download logs: {str(e)}")


class CursesUI:
    """Handles curses UI for displaying pipeline runs and test failures."""

    def __init__(self, stdscr):
        """Initialize curses UI."""
        self.stdscr = stdscr
        self.current_selection = 0
        self.scroll_offset = 0

        # Initialize colors
        curses.start_color()
        curses.init_pair(1, curses.COLOR_BLACK, curses.COLOR_WHITE)  # Selected
        curses.init_pair(2, curses.COLOR_GREEN, curses.COLOR_BLACK)  # Success
        curses.init_pair(3, curses.COLOR_RED, curses.COLOR_BLACK)    # Failed
        curses.init_pair(4, curses.COLOR_YELLOW, curses.COLOR_BLACK) # In Progress
        curses.init_pair(5, curses.COLOR_CYAN, curses.COLOR_BLACK)   # Header

        # Cursor and input settings
        curses.curs_set(0)  # Hide cursor
        self.stdscr.keypad(True)

    def get_status_color(self, status: str, result: str) -> int:
        """Get color pair for build status."""
        if result == "succeeded":
            return 2  # Green
        elif result == "failed":
            return 3  # Red
        elif status == "inProgress":
            return 4  # Yellow
        return 0  # Default

    def draw_runs_list(self, runs: List[Dict[str, Any]], pipeline_name: str):
        """Draw the list of pipeline runs."""
        self.stdscr.clear()
        height, width = self.stdscr.getmaxyx()

        # Header
        header = f"RunRegression Pipeline Runs ({pipeline_name})"
        self.stdscr.addstr(0, 0, header[:width-1], curses.color_pair(5) | curses.A_BOLD)
        self.stdscr.addstr(
            1, 0,
            "Use arrow keys to navigate, Enter to view failures, B to open in browser, Q to quit"[:width-1],
            curses.color_pair(5)
        )

        # Column headers
        header_line = f"{'#':<5} {'Build':<15} {'Status':<12} {'Result':<12} {'Started':<20} {'Branch':<30}"
        self.stdscr.addstr(3, 0, header_line[:width-1], curses.A_BOLD)

        # Calculate visible range
        visible_height = height - 6  # Account for header and footer
        max_scroll = max(0, len(runs) - visible_height)
        self.scroll_offset = max(0, min(self.scroll_offset, max_scroll))

        # Adjust scroll if selection is out of view
        if self.current_selection < self.scroll_offset:
            self.scroll_offset = self.current_selection
        elif self.current_selection >= self.scroll_offset + visible_height:
            self.scroll_offset = self.current_selection - visible_height + 1

        # Draw visible runs
        for idx in range(visible_height):
            run_idx = idx + self.scroll_offset
            if run_idx >= len(runs):
                break

            run = runs[run_idx]

            # Format run data
            build_num = run.get('buildNumber', 'N/A')[:15]
            status = run.get('status', 'unknown')[:12]
            result = run.get('result', 'N/A')[:12]
            start_time = run.get('startTime', '')
            if start_time:
                try:
                    dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
                    start_time = dt.strftime('%Y-%m-%d %H:%M')
                except:
                    start_time = start_time[:20]
            branch = run.get('sourceBranch', '')
            if branch.startswith('refs/heads/'):
                branch = branch[11:]
            branch = branch[:30]

            line = f"{run_idx+1:<5} {build_num:<15} {status:<12} {result:<12} {start_time:<20} {branch:<30}"

            # Apply colors and highlight selection
            y_pos = 4 + idx
            if run_idx == self.current_selection:
                self.stdscr.addstr(y_pos, 0, line[:width-1], curses.color_pair(1))
            else:
                color = self.get_status_color(status, result)
                self.stdscr.addstr(y_pos, 0, line[:width-1], curses.color_pair(color))

        # Footer with scroll indicator
        footer = f"Showing {self.scroll_offset + 1}-{min(self.scroll_offset + visible_height, len(runs))} of {len(runs)}"
        self.stdscr.addstr(height - 1, 0, footer[:width-1], curses.color_pair(5))

        self.stdscr.refresh()

    def draw_failures_list(self, failures: List[Dict[str, Any]], build_number: str,
                          test_selection: int, test_scroll: int):
        """Draw the list of failed tests with selection support."""
        self.stdscr.clear()
        height, width = self.stdscr.getmaxyx()

        # Header
        header = f"Failed Tests for Build {build_number}"
        self.stdscr.addstr(0, 0, header[:width-1], curses.color_pair(5) | curses.A_BOLD)
        self.stdscr.addstr(
            1, 0,
            "Use arrow keys, Enter to download logs, Q/Esc to return"[:width-1],
            curses.color_pair(5)
        )

        if not failures:
            self.stdscr.addstr(3, 0, "No failed tests found!", curses.color_pair(2))
            self.stdscr.refresh()
            return

        # Calculate visible range
        visible_height = height - 5  # Account for header and footer

        # Draw visible failures
        y_pos = 3
        for idx in range(visible_height):
            test_idx = idx + test_scroll
            if test_idx >= len(failures):
                break

            failure = failures[test_idx]
            test_line = f"{failure['run']}: {failure['test']}"

            # Highlight selection
            if test_idx == test_selection:
                self.stdscr.addstr(y_pos, 0, test_line[:width-1], curses.color_pair(1))
            else:
                self.stdscr.addstr(y_pos, 0, test_line[:width-1], curses.color_pair(3))

            y_pos += 1

        # Summary footer
        total_failures = len(failures)
        summary = f"Showing {test_scroll + 1}-{min(test_scroll + visible_height, total_failures)} of {total_failures} failed tests"
        self.stdscr.addstr(height - 1, 0, summary[:width-1], curses.color_pair(5) | curses.A_BOLD)

        self.stdscr.refresh()

    def select_failed_test(self, failures: List[Dict[str, Any]], build_number: str) -> Optional[Dict[str, Any]]:
        """Handle failed test selection with arrow keys."""
        test_selection = 0
        test_scroll = 0

        if not failures:
            self.draw_failures_list(failures, build_number, 0, 0)
            self.stdscr.getch()
            return None

        height, _ = self.stdscr.getmaxyx()
        visible_height = height - 5

        while True:
            # Adjust scroll if selection is out of view
            if test_selection < test_scroll:
                test_scroll = test_selection
            elif test_selection >= test_scroll + visible_height:
                test_scroll = test_selection - visible_height + 1

            self.draw_failures_list(failures, build_number, test_selection, test_scroll)

            key = self.stdscr.getch()

            if key == curses.KEY_UP:
                test_selection = max(0, test_selection - 1)
            elif key == curses.KEY_DOWN:
                test_selection = min(len(failures) - 1, test_selection + 1)
            elif key == ord('\n') or key == curses.KEY_ENTER:
                return failures[test_selection]
            elif key == ord('q') or key == ord('Q') or key == 27:  # 27 is ESC
                return None

    def select_run(self, runs: List[Dict[str, Any]], pipeline_name: str) -> Optional[Dict[str, Any]]:
        """Handle run selection with arrow keys."""
        while True:
            self.draw_runs_list(runs, pipeline_name)

            key = self.stdscr.getch()

            if key == curses.KEY_UP:
                self.current_selection = max(0, self.current_selection - 1)
            elif key == curses.KEY_DOWN:
                self.current_selection = min(len(runs) - 1, self.current_selection + 1)
            elif key == ord('\n') or key == curses.KEY_ENTER:
                return runs[self.current_selection]
            elif key == ord('b') or key == ord('B'):
                # Open build in browser
                import webbrowser
                build_id = runs[self.current_selection]['id']
                url = f"https://dev.azure.com/Avecto-VSTS/Windows/_build/results?buildId={build_id}"
                webbrowser.open(url)
                # Continue showing the list after opening browser
            elif key == ord('q') or key == ord('Q'):
                return None


def main(stdscr):
    """Main entry point for the curses UI."""
    try:
        # Initialize Azure DevOps connection
        azdo = AzDoConnection()

        # Find RunRegression pipeline
        pipeline_name = "RunRegression"
        pipeline_id = azdo.find_pipeline_by_name(pipeline_name)

        if pipeline_id is None:
            stdscr.addstr(0, 0, f"Error: Pipeline '{pipeline_name}' not found!")
            stdscr.addstr(1, 0, "Press any key to exit...")
            stdscr.getch()
            return

        # Get pipeline runs
        stdscr.addstr(0, 0, "Loading pipeline runs...")
        stdscr.refresh()

        runs = azdo.get_pipeline_runs(pipeline_id)

        if not runs:
            stdscr.addstr(0, 0, "No runs found for this pipeline!")
            stdscr.addstr(1, 0, "Press any key to exit...")
            stdscr.getch()
            return

        # Initialize UI
        ui = CursesUI(stdscr)

        # Main loop
        while True:
            selected_run = ui.select_run(runs, pipeline_name)

            if selected_run is None:
                break  # User quit

            # Show loading message
            stdscr.clear()
            build_id = selected_run['id']
            build_number = selected_run.get('buildNumber', str(build_id))
            stdscr.addstr(0, 0, f"Loading test failures for build {build_id} ({build_number})...")
            stdscr.refresh()

            # Get failed tests
            failures = azdo.get_failed_tests(build_id)

            # Silently parse copy job logs to get UNC paths
            test_suite_paths = azdo.parse_copy_job_logs(build_id)

            # Test selection loop
            while True:
                selected_test = ui.select_failed_test(failures, build_number)

                if selected_test is None:
                    break  # User went back

                # Show downloading message
                stdscr.clear()
                stdscr.addstr(0, 0, f"Downloading logs for: {selected_test['test']}")
                stdscr.addstr(1, 0, "Please wait...")
                stdscr.refresh()

                # Download logs
                try:
                    # Find matching UNC path for this test suite
                    unc_path = None
                    run_name = selected_test['run']
                    for suite_name, path in test_suite_paths.items():
                        if suite_name in run_name:
                            unc_path = path
                            break

                    output_dir = azdo.download_test_logs(
                        selected_test['run_id'],
                        selected_test['result_id'],
                        build_id,
                        selected_test['test'],
                        unc_path
                    )

                    # Show success message
                    stdscr.clear()
                    stdscr.addstr(0, 0, "Logs downloaded successfully!", curses.color_pair(2))
                    stdscr.addstr(1, 0, f"Location: {output_dir}")
                    stdscr.addstr(3, 0, "Press any key to continue...")
                    stdscr.refresh()
                    stdscr.getch()

                except Exception as e:
                    # Show error message
                    stdscr.clear()
                    stdscr.addstr(0, 0, "Error downloading logs:", curses.color_pair(3))
                    stdscr.addstr(1, 0, str(e)[:stdscr.getmaxyx()[1] - 1])
                    stdscr.addstr(3, 0, "Press any key to continue...")
                    stdscr.refresh()
                    stdscr.getch()

    except Exception as e:
        stdscr.clear()
        stdscr.addstr(0, 0, f"Error: {str(e)}")
        stdscr.addstr(1, 0, "Press any key to exit...")
        stdscr.refresh()
        stdscr.getch()


if __name__ == "__main__":
    try:
        curses.wrapper(main)
    except KeyboardInterrupt:
        print("\nExited by user")
        sys.exit(0)
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
